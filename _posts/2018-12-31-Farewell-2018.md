---
layout: post
title: My AI journey in 2018 
---

My motivation of writing this very first blog at the last day of 2018 came from a casual conversation between me and my boyfriend. He said he would look back what he achieved for the last 12 months and felt proud, which reminded me of a Chinese meme 
![meme](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1546241975898&di=50d577401859affd3c89f4442507d05a&imgtype=0&src=http%3A%2F%2Fniuerdata.donews.com%2Fdata%2Fshareimg_oss%2Fbig_media_img%2F2018%2F01%2F02%2F0fac0c231220537e12fcbe89df7f387b.JPEG) 
where people make a small twist of their last year’s resolutions. I thought 2018 was just another  plain old year, but wait, maybe it wasn’t. In 2018, I just started my AI journey, an exciting path I have never set foot on, with the right tool and a little bit of imagination. 

At the start of the year, I came across a [AlphaGo Documentary](https://www.youtube.com/watch?v=9gzMQOa5MD4) made by DeepMind, which highlighted the winning strategies of AlphaGo and the epic match between machine and human. Although it was heartbroken to watch human master Lee Sedol lose, I released how Reinforcement Learning can beat the record in traditionally human-dominated fields. 
![Go match](https://media.wired.com/photos/592720e2cefba457b079c319/master/w_1164,c_limit/GW20160133774.jpg)
And that was when I decided to learn AI. 

I got my first machine Learning internship with [Cognitive Systems Corp](https://www.cognitivesystems.com/) in the summer of 2018. The startup focuses on solving motion detection problem using radio frequency in a WiFi environment. When I just started, I had very little knowledge about signal processing and various machine learning algorithms. I remember I tried out VGG-16 on time frequency signal data and the accuracy went from 30% to 50%, which was like tossing a coin :sweat_smile: After many times of failure, I gradually learned the importance of preprocessing data and customizing the right models to every unique task. Meanwhile, there were space and time requirements for algorithms to run on an embedded device. Even sorting became a challenging thing to do in time every 0.1 second. During four months of intern, machine learning boiled down to Mathematics, Statistics, and computer science, which were far beyond running state-of-the-art algorithms!

**This is not a technical post if you just realized**

To be honest, I was a bit disappointed when my Cali dream got bursted. My second machine learning intern was also in Canada from September to December. During my first two months ~~of being a web developer~~ at IBM, I become acquainted with a PHD who was doing all kinds of fascinating data science work. He gave me a face recognition task and a pile of latest papers :massage: This time, running state-of-the-art algorithms does matter! I got the chance to design the whole algorithm from end to end, including Raspberry Pi setup, data streaming, and hyper-parameter tuning. The moral of this story: Reading papers is equally important.

Luckily, I was not alone on this AI journey. In October, I found my boyfriend whom I love very much and he also loves data science especially Natural Language Processing (NLP). He inspired me to build a NLP project that can analyze sentiment in Chinese conversational text. Hopefully I can do my first commit in the near future. And that ends my AI journey in 2018. Thanks for spending time reading and happy new year!! :tada: :gift_heart: :pig:
